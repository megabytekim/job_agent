"""
Job Agent implemented with LangGraph and Vertex AI Gemini.
"""

from langchain_google_vertexai import ChatVertexAI
from langchain_core.tools import tool
from langgraph.prebuilt import create_react_agent
from langgraph.checkpoint.memory import MemorySaver
from pydantic import BaseModel
import uuid
from dotenv import load_dotenv
import os
from typing import Any, List

load_dotenv()

memory = MemorySaver()


# LinkedIn API ì—°ë™ ì‹œ ì‚¬ìš©í•  ëª¨ë¸ë“¤ (í–¥í›„ êµ¬í˜„ ì˜ˆì •)
# class JobRecommendation(BaseModel):
#     job_id: str
#     title: str
#     company: str
#     location: str
#     salary_range: str
#     description: str
#     requirements: list[str]

# class JobSearchResult(BaseModel):
#     search_id: str
#     query: str
#     recommendations: list[JobRecommendation]
#     total_found: int


@tool
def search_jobs(query: str, location: str = "Remote", experience_level: str = "Entry") -> str:
    """
    Searches for job opportunities on LinkedIn based on the given criteria.
    Note: LinkedIn API integration is planned for future implementation.

    Args:
        query: Job title or keywords to search for
        location: Preferred location (default: Remote)
        experience_level: Experience level (Entry, Mid, Senior)

    Returns:
        str: A message about LinkedIn job search functionality.
    """
    try:
        # Check if user is asking for LinkedIn job search
        linkedin_keywords = ["linkedin", "ë§í¬ë“œì¸", "linkedin jobs", "linkedinì—ì„œ", "linkedinìœ¼ë¡œ"]
        is_linkedin_request = any(keyword in query.lower() for keyword in linkedin_keywords)
        
        if is_linkedin_request:
            return (
                f"LinkedInì—ì„œ '{query}' ê´€ë ¨ êµ¬ì§ ê²€ìƒ‰ì„ ìš”ì²­í•˜ì…¨êµ°ìš”! "
                "í˜„ì¬ LinkedIn API ì—°ë™ ê¸°ëŠ¥ì€ ê°œë°œ ì¤‘ì´ë©°, ê³§ ì‹¤ì œ LinkedIn êµ¬ì§ ì •ë³´ë¥¼ ê²€ìƒ‰í•  ìˆ˜ ìˆë„ë¡ ì—…ë°ì´íŠ¸ë  ì˜ˆì •ì…ë‹ˆë‹¤. "
                "ì§€ê¸ˆì€ ì»¤ë¦¬ì–´ ì¡°ì–¸ì´ë‚˜ ì´ë ¥ì„œ ì‘ì„± íŒ ë“± ë‹¤ë¥¸ ë„ì›€ì„ ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
            )
        else:
            return (
                f"'{query}' ê´€ë ¨ êµ¬ì§ ê¸°íšŒë¥¼ ì°¾ê³  ê³„ì‹œëŠ”êµ°ìš”! "
                "í˜„ì¬ LinkedIn API ì—°ë™ ê¸°ëŠ¥ì€ ê°œë°œ ì¤‘ì´ë©°, ê³§ ì‹¤ì œ êµ¬ì§ ì •ë³´ë¥¼ ê²€ìƒ‰í•  ìˆ˜ ìˆë„ë¡ ì—…ë°ì´íŠ¸ë  ì˜ˆì •ì…ë‹ˆë‹¤. "
                "ì§€ê¸ˆì€ ì»¤ë¦¬ì–´ ì¡°ì–¸, ì´ë ¥ì„œ ì‘ì„± íŒ, ë©´ì ‘ ì¤€ë¹„ ë“± ë‹¤ë¥¸ ë„ì›€ì„ ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
            )
        
    except Exception as e:
        print(f"Error in search_jobs: {e}")
        return f"êµ¬ì§ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"


class JobAgent:
    SYSTEM_INSTRUCTION = """
# ì§€ì¹¨

ë‹¹ì‹ ì€ ì „ë¬¸ì ì¸ ì»¤ë¦¬ì–´ ë° ì·¨ì—… ìƒë‹´ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.
ì‚¬ìš©ìì˜ ì»¤ë¦¬ì–´ ì¡°ì–¸, ì·¨ì—… í™œë™, ì´ë ¥ì„œ íŒ, ë©´ì ‘ ì¤€ë¹„, ê·¸ë¦¬ê³  ì „ë¬¸ì„± ê°œë°œì„ ë„ì™€ì£¼ëŠ” ê²ƒì´ ëª©ì ì…ë‹ˆë‹¤.
ë‹¤ì–‘í•œ ì»¤ë¦¬ì–´ ê´€ë ¨ ì£¼ì œì— ëŒ€í•œ ê°€ì´ë“œë¥¼ ì œê³µí•˜ê³  ì·¨ì—… ê¸°íšŒë¥¼ ì°¾ì„ ìˆ˜ ìˆë„ë¡ ë„ì™€ì¤ë‹ˆë‹¤.

# ë§¥ë½

ë‹¤ìŒê³¼ ê°™ì€ ë„ì›€ì„ ì œê³µí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:
- ì·¨ì—… ì „ëµ ë° ê¸°ë²•
- ì´ë ¥ì„œ ì‘ì„± ë° ìµœì í™”
- ë©´ì ‘ ì¤€ë¹„ ë° íŒ
- ì»¤ë¦¬ì–´ ê²½ë¡œ ê°€ì´ë“œ
- ì—°ë´‰ í˜‘ìƒ ì¡°ì–¸
- ì „ë¬¸ì„± ê°œë°œ ê³„íš
- ì—…ê³„ ì¸ì‚¬ì´íŠ¸ ë° íŠ¸ë Œë“œ
- ë„¤íŠ¸ì›Œí‚¹ ì „ëµ

# ê·œì¹™

- ì „ë¬¸ì ì´ê³  ê²©ë ¤ì ì´ë©° ì§€ì§€ì ì¸ ì‘ë‹µì„ ì œê³µí•˜ì„¸ìš”
- ì‹¤ìš©ì ì´ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ ì¡°ì–¸ì„ ì œê³µí•˜ì„¸ìš”
- ì‚¬ìš©ìê°€ êµ¬ì²´ì ì¸ ì±„ìš© ì •ë³´ë¥¼ ìš”ì²­í•˜ë©´ `search_jobs` ë„êµ¬ë¥¼ ì‚¬ìš©í•´ ê´€ë ¨ ê¸°íšŒë¥¼ ì°¾ì•„ì£¼ì„¸ìš”
- ì»¤ë¦¬ì–´ ê´€ë ¨ ì¼ë°˜ì ì¸ ì›¹ ê²€ìƒ‰ì€ `web_search` ë„êµ¬ë¥¼ ì‚¬ìš©í•´ ìµœì‹  ì •ë³´ë¥¼ ì œê³µí•˜ì„¸ìš”
- í•­ìƒ ì‚¬ìš©ìì˜ ê²½í—˜ ìˆ˜ì¤€ê³¼ ì»¤ë¦¬ì–´ ëª©í‘œë¥¼ ê³ ë ¤í•˜ì„¸ìš”
- ìƒí™©ì— ë§ëŠ” ê°œì¸í™”ëœ ì¶”ì²œì„ ì œê³µí•˜ì„¸ìš”
- ì»¤ë¦¬ì–´/ì·¨ì—… ì¡°ì–¸ ë²”ìœ„ë¥¼ ë²—ì–´ë‚œ ì£¼ì œì— ëŒ€í•´ì„œëŠ” ì •ì¤‘í•˜ê²Œ ì»¤ë¦¬ì–´ ê´€ë ¨ ì£¼ì œë¡œ ì•ˆë‚´í•˜ì„¸ìš”
- ì „ë¬¸ì„±ì„ ìœ ì§€í•˜ë©´ì„œë„ ì¹œê·¼í•˜ê³  ëŒ€í™”í•˜ê¸° ì‰¬ìš´ í†¤ì„ ì‚¬ìš©í•˜ì„¸ìš”
- í•œ ë²ˆì— í•˜ë‚˜ì˜ ëª…í™•í•œ ì‘ë‹µë§Œ ì œê³µí•˜ì„¸ìš”
 - ë„êµ¬(web_search, search_jobs)ë¥¼ ì‹¤ì œë¡œ í˜¸ì¶œí•˜ì§€ ì•ŠëŠ” ì´ìƒ "ê²€ìƒ‰ ì¤‘ì…ë‹ˆë‹¤", "ì°¾ì•„ë³´ê² ìŠµë‹ˆë‹¤" ë“± ì™¸ë¶€ ê²€ìƒ‰/ì¡°íšŒ ìˆ˜í–‰ì„ ì•”ì‹œí•˜ëŠ” í‘œí˜„ì„ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”
 - ì‚¬ìš©ìê°€ LinkedIn(ë§í¬ë“œì¸) êµ¬ì§ ê²€ìƒ‰ì„ ìš”ì²­í•˜ë©´, í˜„ì¬ LinkedIn API ì—°ë™ì€ ì¤€ë¹„ ì¤‘ì„ì„ ëª…í™•íˆ ì•Œë¦¬ê³  ëŒ€ì•ˆì„ ì œì‹œí•˜ì„¸ìš” (ì˜ˆ: ì—­í• /ê²½ë ¥/ì§€ì—­ì„ ê¸°ë°˜ìœ¼ë¡œ í•œ ì¼ë°˜ì  ì¡°ì–¸)
"""
    SUPPORTED_CONTENT_TYPES = ["text", "text/plain"]

    def __init__(self):
        self.model = ChatVertexAI(
            model="gemini-2.5-flash-lite",
            location=os.getenv("GOOGLE_CLOUD_LOCATION"),
            project=os.getenv("GOOGLE_CLOUD_PROJECT"),
            temperature=0,
        )
        # Base tools
        tool_list: List[Any] = [search_jobs]

        # Optionally load MCP tools from local web_search_server (no API key required)
        # Since MCP client loading is async and complex, add direct web_search tool for now
        try:
            print("ğŸ” Adding web search tool...")
            # Import the web search functionality directly
            current_dir = os.path.dirname(os.path.abspath(__file__))
            server_path = os.path.join(current_dir, "web_search_server.py")
            print(f"ğŸ“ MCP server path: {server_path}")
            print(f"ğŸ“„ Server exists: {os.path.exists(server_path)}")
            
            if os.path.exists(server_path):
                # Import duckduckgo search function directly
                try:
                    from ddgs import DDGS
                    import json

                    @tool
                    def web_search(query: str, count: int = 5) -> str:
                        """Perform a web search and return top results.

                        Args:
                            query: Search query string
                            count: Number of results to return (default 5)

                        Returns:
                            String containing search results with titles and descriptions
                        """
                        try:
                            results = []
                            with DDGS() as ddgs:
                                for r in ddgs.text(query, max_results=count):
                                    results.append({
                                        "title": r.get("title"),
                                        "href": r.get("href"),
                                        "body": r.get("body"),
                                    })
                            
                            # Format results for better readability
                            formatted = []
                            for i, result in enumerate(results, 1):
                                formatted.append(f"{i}. {result['title']}\n   URL: {result['href']}\n   Summary: {result['body'][:200]}...")
                            
                            return "\n\n".join(formatted)
                        except Exception as e:
                            return f"Search failed: {e}"

                    tool_list.append(web_search)
                    print("âœ… Added direct web_search tool")
                except ImportError:
                    print("âš ï¸ ddgs package not available, skipping web search")
        except Exception as e:
            # If MCP libs are not available, proceed with built-in tools only
            print(f"âŒ Web search tool loading failed: {e}")
            import traceback
            traceback.print_exc()

        self.tools = tool_list
        self.graph = create_react_agent(
            self.model,
            tools=self.tools,
            checkpointer=memory,
            prompt=self.SYSTEM_INSTRUCTION,
        )

    def invoke(self, query, sessionId) -> str:
        # Early handling: If the user explicitly asks for LinkedIn job search, respond deterministically
        try:
            linkedin_keywords = ["linkedin", "ë§í¬ë“œì¸", "linkedin jobs", "linkedinì—ì„œ", "linkedinìœ¼ë¡œ"]
            if any(k in str(query).lower() for k in linkedin_keywords):
                return (
                    "LinkedIn êµ¬ì§ ê²€ìƒ‰ ê¸°ëŠ¥ì€ í˜„ì¬ API ì—°ë™ ì¤€ë¹„ ì¤‘ì…ë‹ˆë‹¤. "
                    "ì›í•˜ì‹œë©´ ì§ë¬´/ê²½ë ¥/ì§€ì—­ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì¼ë°˜ì ì¸ êµ¬ì§ ì „ëµ, ì´ë ¥ì„œ/ìê¸°ì†Œê°œì„œ ê°œì„ , ë©´ì ‘ ì¤€ë¹„ íŒì„ ì œê³µí•´ ë“œë¦´ê²Œìš”."
                )
        except Exception:
            # Fall through to normal handling if any error occurs in the guard
            pass

        config = {"configurable": {"thread_id": sessionId}}
        
        # LangGraph invokeë¥¼ í†µí•´ ì‘ë‹µ ìƒì„±
        result = self.graph.invoke({"messages": [("user", query)]}, config)
        
        # ë§ˆì§€ë§‰ AI ë©”ì‹œì§€ë§Œ ë°˜í™˜ (ì¤‘ë³µ ë°©ì§€)
        messages = result.get("messages", [])
        
        # AI ë©”ì‹œì§€ë“¤ ì¤‘ ë§ˆì§€ë§‰ í•˜ë‚˜ë§Œ ê°€ì ¸ì˜¤ê¸°
        ai_messages = [msg for msg in messages if hasattr(msg, 'type') and msg.type == 'ai']
        if ai_messages:
            return ai_messages[-1].content
        
        # ì¼ë°˜ ë©”ì‹œì§€ì—ì„œ ë§ˆì§€ë§‰ í•˜ë‚˜ ê°€ì ¸ì˜¤ê¸° (fallback)
        if messages:
            return messages[-1].content
            
        return "ì£„ì†¡í•©ë‹ˆë‹¤. ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."


