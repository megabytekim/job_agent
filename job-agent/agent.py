"""
Job Agent implemented with LangGraph and Vertex AI Gemini.
"""

from langchain_google_vertexai import ChatVertexAI
from langchain_core.tools import tool
from langgraph.prebuilt import create_react_agent
from langgraph.checkpoint.memory import MemorySaver
from pydantic import BaseModel
import uuid
from dotenv import load_dotenv
import os
from typing import Any, List

load_dotenv()

memory = MemorySaver()


class JobRecommendation(BaseModel):
    job_id: str
    title: str
    company: str
    location: str
    salary_range: str
    description: str
    requirements: list[str]


class JobSearchResult(BaseModel):
    search_id: str
    query: str
    recommendations: list[JobRecommendation]
    total_found: int


@tool
def search_jobs(query: str, location: str = "Remote", experience_level: str = "Entry") -> str:
    """
    Searches for job opportunities based on the given criteria.

    Args:
        query: Job title or keywords to search for
        location: Preferred location (default: Remote)
        experience_level: Experience level (Entry, Mid, Senior)

    Returns:
        str: A message with job search results and recommendations.
    """
    try:
        search_id = str(uuid.uuid4())
        
        # Mock job recommendations based on query
        mock_jobs = [
            JobRecommendation(
                job_id=str(uuid.uuid4()),
                title=f"{query} Developer",
                company="Tech Corp",
                location=location,
                salary_range="$60K - $80K",
                description=f"Looking for a {query} developer to join our team",
                requirements=["Python", "JavaScript", "2+ years experience"]
            ),
            JobRecommendation(
                job_id=str(uuid.uuid4()),
                title=f"Senior {query} Engineer",
                company="Innovation Inc",
                location=location,
                salary_range="$100K - $130K",
                description=f"Senior role in {query} development",
                requirements=["5+ years experience", "Leadership skills", "Advanced programming"]
            )
        ]
        
        result = JobSearchResult(
            search_id=search_id,
            query=query,
            recommendations=mock_jobs,
            total_found=len(mock_jobs)
        )
        
        print("===")
        print(f"Job search completed: {result}")
        print("===")
        
        return f"Found {result.total_found} jobs for '{query}' in {location}. Search ID: {search_id}"
        
    except Exception as e:
        print(f"Error searching jobs: {e}")
        return f"Error searching jobs: {e}"


class JobAgent:
    SYSTEM_INSTRUCTION = """
# ì§€ì¹¨

ë‹¹ì‹ ì€ ì „ë¬¸ì ì¸ ì»¤ë¦¬ì–´ ë° ì·¨ì—… ìƒë‹´ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.
ì‚¬ìš©ìì˜ ì»¤ë¦¬ì–´ ì¡°ì–¸, ì·¨ì—… í™œë™, ì´ë ¥ì„œ íŒ, ë©´ì ‘ ì¤€ë¹„, ê·¸ë¦¬ê³  ì „ë¬¸ì„± ê°œë°œì„ ë„ì™€ì£¼ëŠ” ê²ƒì´ ëª©ì ì…ë‹ˆë‹¤.
ë‹¤ì–‘í•œ ì»¤ë¦¬ì–´ ê´€ë ¨ ì£¼ì œì— ëŒ€í•œ ê°€ì´ë“œë¥¼ ì œê³µí•˜ê³  ì·¨ì—… ê¸°íšŒë¥¼ ì°¾ì„ ìˆ˜ ìˆë„ë¡ ë„ì™€ì¤ë‹ˆë‹¤.

# ë§¥ë½

ë‹¤ìŒê³¼ ê°™ì€ ë„ì›€ì„ ì œê³µí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:
- ì·¨ì—… ì „ëµ ë° ê¸°ë²•
- ì´ë ¥ì„œ ì‘ì„± ë° ìµœì í™”
- ë©´ì ‘ ì¤€ë¹„ ë° íŒ
- ì»¤ë¦¬ì–´ ê²½ë¡œ ê°€ì´ë“œ
- ì—°ë´‰ í˜‘ìƒ ì¡°ì–¸
- ì „ë¬¸ì„± ê°œë°œ ê³„íš
- ì—…ê³„ ì¸ì‚¬ì´íŠ¸ ë° íŠ¸ë Œë“œ
- ë„¤íŠ¸ì›Œí‚¹ ì „ëµ

# ê·œì¹™

- ì „ë¬¸ì ì´ê³  ê²©ë ¤ì ì´ë©° ì§€ì§€ì ì¸ ì‘ë‹µì„ ì œê³µí•˜ì„¸ìš”
- ì‹¤ìš©ì ì´ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ ì¡°ì–¸ì„ ì œê³µí•˜ì„¸ìš”
- ì‚¬ìš©ìê°€ êµ¬ì²´ì ì¸ ì±„ìš© ì •ë³´ë¥¼ ìš”ì²­í•˜ë©´ `search_jobs` ë„êµ¬ë¥¼ ì‚¬ìš©í•´ ê´€ë ¨ ê¸°íšŒë¥¼ ì°¾ì•„ì£¼ì„¸ìš”
- ì»¤ë¦¬ì–´ ê´€ë ¨ ì¼ë°˜ì ì¸ ì›¹ ê²€ìƒ‰ì€ `web_search` ë„êµ¬ë¥¼ ì‚¬ìš©í•´ ìµœì‹  ì •ë³´ë¥¼ ì œê³µí•˜ì„¸ìš”
- í•­ìƒ ì‚¬ìš©ìì˜ ê²½í—˜ ìˆ˜ì¤€ê³¼ ì»¤ë¦¬ì–´ ëª©í‘œë¥¼ ê³ ë ¤í•˜ì„¸ìš”
- ìƒí™©ì— ë§ëŠ” ê°œì¸í™”ëœ ì¶”ì²œì„ ì œê³µí•˜ì„¸ìš”
- ì»¤ë¦¬ì–´/ì·¨ì—… ì¡°ì–¸ ë²”ìœ„ë¥¼ ë²—ì–´ë‚œ ì£¼ì œì— ëŒ€í•´ì„œëŠ” ì •ì¤‘í•˜ê²Œ ì»¤ë¦¬ì–´ ê´€ë ¨ ì£¼ì œë¡œ ì•ˆë‚´í•˜ì„¸ìš”
- ì „ë¬¸ì„±ì„ ìœ ì§€í•˜ë©´ì„œë„ ì¹œê·¼í•˜ê³  ëŒ€í™”í•˜ê¸° ì‰¬ìš´ í†¤ì„ ì‚¬ìš©í•˜ì„¸ìš”
- í•œ ë²ˆì— í•˜ë‚˜ì˜ ëª…í™•í•œ ì‘ë‹µë§Œ ì œê³µí•˜ì„¸ìš”
"""
    SUPPORTED_CONTENT_TYPES = ["text", "text/plain"]

    def __init__(self):
        self.model = ChatVertexAI(
            model="gemini-2.5-flash-lite",
            location=os.getenv("GOOGLE_CLOUD_LOCATION"),
            project=os.getenv("GOOGLE_CLOUD_PROJECT"),
        )
        # Base tools
        tool_list: List[Any] = [search_jobs]

        # Optionally load MCP tools from local web_search_server (no API key required)
        # Since MCP client loading is async and complex, add direct web_search tool for now
        try:
            print("ğŸ” Adding web search tool...")
            # Import the web search functionality directly
            current_dir = os.path.dirname(os.path.abspath(__file__))
            server_path = os.path.join(current_dir, "web_search_server.py")
            print(f"ğŸ“ MCP server path: {server_path}")
            print(f"ğŸ“„ Server exists: {os.path.exists(server_path)}")
            
            if os.path.exists(server_path):
                # Import duckduckgo search function directly
                try:
                    from ddgs import DDGS
                    import json

                    @tool
                    def web_search(query: str, count: int = 5) -> str:
                        """Perform a web search and return top results.

                        Args:
                            query: Search query string
                            count: Number of results to return (default 5)

                        Returns:
                            String containing search results with titles and descriptions
                        """
                        try:
                            results = []
                            with DDGS() as ddgs:
                                for r in ddgs.text(query, max_results=count):
                                    results.append({
                                        "title": r.get("title"),
                                        "href": r.get("href"),
                                        "body": r.get("body"),
                                    })
                            
                            # Format results for better readability
                            formatted = []
                            for i, result in enumerate(results, 1):
                                formatted.append(f"{i}. {result['title']}\n   URL: {result['href']}\n   Summary: {result['body'][:200]}...")
                            
                            return "\n\n".join(formatted)
                        except Exception as e:
                            return f"Search failed: {e}"

                    tool_list.append(web_search)
                    print("âœ… Added direct web_search tool")
                except ImportError:
                    print("âš ï¸ ddgs package not available, skipping web search")
        except Exception as e:
            # If MCP libs are not available, proceed with built-in tools only
            print(f"âŒ Web search tool loading failed: {e}")
            import traceback
            traceback.print_exc()

        self.tools = tool_list
        self.graph = create_react_agent(
            self.model,
            tools=self.tools,
            checkpointer=memory,
            prompt=self.SYSTEM_INSTRUCTION,
        )

    def invoke(self, query, sessionId) -> str:
        config = {"configurable": {"thread_id": sessionId}}
        
        # LangGraph invokeë¥¼ í†µí•´ ì‘ë‹µ ìƒì„±
        result = self.graph.invoke({"messages": [("user", query)]}, config)
        
        # ë§ˆì§€ë§‰ AI ë©”ì‹œì§€ë§Œ ë°˜í™˜ (ì¤‘ë³µ ë°©ì§€)
        messages = result.get("messages", [])
        
        # AI ë©”ì‹œì§€ë“¤ ì¤‘ ë§ˆì§€ë§‰ í•˜ë‚˜ë§Œ ê°€ì ¸ì˜¤ê¸°
        ai_messages = [msg for msg in messages if hasattr(msg, 'type') and msg.type == 'ai']
        if ai_messages:
            return ai_messages[-1].content
        
        # ì¼ë°˜ ë©”ì‹œì§€ì—ì„œ ë§ˆì§€ë§‰ í•˜ë‚˜ ê°€ì ¸ì˜¤ê¸° (fallback)
        if messages:
            return messages[-1].content
            
        return "ì£„ì†¡í•©ë‹ˆë‹¤. ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."


